{"cells":[{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T12:28:49.912610Z","iopub.status.busy":"2024-11-30T12:28:49.912288Z","iopub.status.idle":"2024-11-30T12:28:49.917232Z","shell.execute_reply":"2024-11-30T12:28:49.916388Z","shell.execute_reply.started":"2024-11-30T12:28:49.912583Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Device configuration\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T12:28:49.974413Z","iopub.status.busy":"2024-11-30T12:28:49.974110Z","iopub.status.idle":"2024-11-30T12:28:49.978843Z","shell.execute_reply":"2024-11-30T12:28:49.977963Z","shell.execute_reply.started":"2024-11-30T12:28:49.974386Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","# RMSE Loss\n","def rmse_loss(predictions, targets):\n","    return torch.sqrt(F.mse_loss(predictions, targets))"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T12:28:50.038754Z","iopub.status.busy":"2024-11-30T12:28:50.037997Z","iopub.status.idle":"2024-11-30T12:28:50.047439Z","shell.execute_reply":"2024-11-30T12:28:50.046026Z","shell.execute_reply.started":"2024-11-30T12:28:50.038724Z"},"trusted":true},"outputs":[],"source":["# Data preparation\n","def load_and_process_data():\n","    # Load the Ratings data\n","    data = pd.read_csv('ml-100k/u.data', sep=\"\\t\", header=None)\n","    data.columns = ['user id', 'movie id', 'rating', 'timestamp']\n","    \n","    # Load the User data\n","    users = pd.read_csv('ml-100k/u.user', sep=\"|\", encoding='latin-1', header=None)\n","    users.columns = ['user id', 'age', 'gender', 'occupation', 'zip code']\n","    \n","    # Load Movie data\n","    items = pd.read_csv('ml-100k/u.item', sep=\"|\", encoding='latin-1', header=None)\n","    items.columns = ['movie id', 'movie title', 'release date', 'video release date', 'IMDb URL', \n","                     'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', \n","                     'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', \n","                     'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n","\n","    # Merge datasets\n","    dataset = data.merge(users, on='user id', how='left').merge(items, on='movie id', how='left')\n","\n","    # Encode categorical features\n","    label_encoder = LabelEncoder()\n","    dataset['gender'] = (dataset['gender'] == 'M').astype(int)\n","    dataset['occupation'] = label_encoder.fit_transform(dataset['occupation'])\n","\n","    # Convert age into intervals (bins) and encode as integers\n","    bins = [0, 18, 25, 35, 45, 50, 60, 100]\n","    labels = [0, 1, 2, 3, 4, 5, 6]\n","    dataset['age'] = pd.cut(dataset['age'], bins=bins, labels=labels).astype(int)\n","\n","    # Normalize ratings\n","    dataset['rating'] = dataset['rating'] / dataset['rating'].max()\n","\n","    # Drop irrelevant columns\n","    dataset.drop(['zip code', 'movie title', 'release date', 'IMDb URL', 'timestamp'], axis=1, inplace=True)\n","\n","    # Split into train, validation, and test sets\n","    train_data, temp_data = train_test_split(dataset, test_size=0.3, random_state=42)\n","    valid_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n","\n","    return train_data, valid_data, test_data"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T12:28:50.049050Z","iopub.status.busy":"2024-11-30T12:28:50.048774Z","iopub.status.idle":"2024-11-30T12:28:50.061693Z","shell.execute_reply":"2024-11-30T12:28:50.060831Z","shell.execute_reply.started":"2024-11-30T12:28:50.049024Z"},"trusted":true},"outputs":[],"source":["class MovieLensDataset(Dataset):\n","    def __init__(self, data, field_dims, device):\n","        self.data = data\n","        self.field_dims = field_dims\n","        self.numerical_cols = data.columns.difference(['rating'])\n","        self.target_col = 'rating'\n","        self.device = device\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        row = self.data.iloc[idx]\n","        features = torch.tensor(row[self.numerical_cols].values, dtype=torch.long, device=self.device)  # Long type\n","        target = torch.tensor(row[self.target_col], dtype=torch.float32, device=self.device)  # Float type\n","        return features, target"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T12:28:50.108935Z","iopub.status.busy":"2024-11-30T12:28:50.108722Z","iopub.status.idle":"2024-11-30T12:28:50.118017Z","shell.execute_reply":"2024-11-30T12:28:50.117121Z","shell.execute_reply.started":"2024-11-30T12:28:50.108914Z"},"trusted":true},"outputs":[],"source":["class DeepFM(nn.Module):\n","    def __init__(self, field_dims, num_factors, mlp_dims, drop_rate=0.1):\n","        \"\"\"\n","        Args:\n","            field_dims (list): List of integers where each entry is the number of unique values for a feature field.\n","            num_factors (int): Size of the embedding vector for each field.\n","            mlp_dims (list): List of integers defining the number of units in each MLP layer.\n","            drop_rate (float): Dropout rate for MLP layers.\n","        \"\"\"\n","        super(DeepFM, self).__init__()\n","        self.num_fields = len(field_dims)\n","        self.num_factors = num_factors\n","\n","        # Embedding layers for each field\n","        self.embeddings = nn.ModuleList([\n","            nn.Embedding(field_dim, num_factors) for field_dim in field_dims\n","        ])\n","\n","        # Linear part (first-order terms)\n","        self.linear_layers = nn.ModuleList([\n","            nn.Embedding(field_dim, 1) for field_dim in field_dims\n","        ])\n","\n","        # Multi-Layer Perceptron (MLP) for deep part\n","        input_dim = self.num_fields * num_factors  # Corrected input dimension\n","        mlp_layers = []\n","        for dim in mlp_dims:\n","            mlp_layers.append(nn.Linear(input_dim, dim))\n","            mlp_layers.append(nn.ReLU())\n","            mlp_layers.append(nn.Dropout(drop_rate))\n","            input_dim = dim\n","        self.mlp = nn.Sequential(*mlp_layers)\n","\n","        # Final layer for deep part output\n","        self.mlp_output = nn.Linear(input_dim, 1)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of DeepFM.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor of shape (batch_size, num_fields).\n","\n","        Returns:\n","            torch.Tensor: Output tensor of shape (batch_size, 1).\n","        \"\"\"\n","        # Embedding lookup\n","        embed_x = torch.cat([\n","            embed(x[:, i]).unsqueeze(1) for i, embed in enumerate(self.embeddings)\n","        ], dim=1)  # Shape: (batch_size, num_fields, num_factors)\n","\n","        # FM: Second-order interactions\n","        square_of_sum = torch.sum(embed_x, dim=1) ** 2\n","        sum_of_square = torch.sum(embed_x ** 2, dim=1)\n","        fm_second_order = 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)\n","\n","        # Linear part (first-order terms)\n","        linear_part = torch.cat([\n","            linear(x[:, i]).unsqueeze(1) for i, linear in enumerate(self.linear_layers)\n","        ], dim=1).sum(1)  # Shape: (batch_size, 1)\n","\n","        # Deep part (MLP)\n","        deep_input = embed_x.view(embed_x.size(0), -1)  # Flatten embeddings to (batch_size, num_fields * num_factors)\n","        deep_output = self.mlp(deep_input)\n","        deep_output = self.mlp_output(deep_output)\n","\n","        # Final output\n","        output = linear_part + fm_second_order + deep_output\n","        return torch.sigmoid(output)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T12:28:50.119718Z","iopub.status.busy":"2024-11-30T12:28:50.119463Z","iopub.status.idle":"2024-11-30T12:28:50.134665Z","shell.execute_reply":"2024-11-30T12:28:50.133849Z","shell.execute_reply.started":"2024-11-30T12:28:50.119693Z"},"trusted":true},"outputs":[],"source":["def train_deepfm(model, train_loader, valid_loader, test_loader, num_epochs=10, lr=1e-3):\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","\n","    best_valid_loss = float('inf')\n","    best_model_state = None\n","\n","    for epoch in range(num_epochs):\n","        # Training\n","        model.train()\n","        train_loss = 0\n","        for features, target in train_loader:\n","            optimizer.zero_grad()\n","            predictions = model(features)\n","            loss = rmse_loss(predictions, target)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","        \n","        train_loss /= len(train_loader)\n","\n","        # Validation\n","        model.eval()\n","        valid_loss = 0\n","        with torch.no_grad():\n","            for features, target in valid_loader:\n","                predictions = model(features)\n","                loss = rmse_loss(predictions, target)\n","                valid_loss += loss.item()\n","        \n","        valid_loss /= len(valid_loader)\n","\n","        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}\")\n","\n","        # Save the best model\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            best_model_state = model.state_dict()\n","\n","    print(f\"Training completed. Best Validation Loss: {best_valid_loss:.4f}\")\n","\n","    # Load the best model state\n","    model.load_state_dict(best_model_state)\n","\n","    # Test the model\n","    model.eval()\n","    test_loss = 0\n","    with torch.no_grad():\n","        for features, target in test_loader:\n","            predictions = model(features)\n","            loss = rmse_loss(predictions, target)\n","            test_loss += loss.item()\n","    \n","    test_loss /= len(test_loader)\n","    print(f\"Test Loss: {test_loss:.4f}\")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T12:28:50.135740Z","iopub.status.busy":"2024-11-30T12:28:50.135499Z","iopub.status.idle":"2024-11-30T12:28:50.258892Z","shell.execute_reply":"2024-11-30T12:28:50.258220Z","shell.execute_reply.started":"2024-11-30T12:28:50.135709Z"},"trusted":true},"outputs":[],"source":["train_data, valid_data, test_data = load_and_process_data()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["user id               622.0\n","movie id              206.0\n","rating                  0.2\n","age                     1.0\n","gender                  1.0\n","occupation             14.0\n","video release date      NaN\n","unknown                 0.0\n","Action                  0.0\n","Adventure               1.0\n","Animation               1.0\n","Children's              0.0\n","Comedy                  0.0\n","Crime                   0.0\n","Documentary             0.0\n","Drama                   0.0\n","Fantasy                 0.0\n","Film-Noir               0.0\n","Horror                  0.0\n","Musical                 0.0\n","Mystery                 0.0\n","Romance                 0.0\n","Sci-Fi                  1.0\n","Thriller                1.0\n","War                     0.0\n","Western                 0.0\n","Name: 60406, dtype: float64"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["train_data.iloc[1]"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T12:28:50.260624Z","iopub.status.busy":"2024-11-30T12:28:50.260390Z","iopub.status.idle":"2024-11-30T12:28:50.270595Z","shell.execute_reply":"2024-11-30T12:28:50.269836Z","shell.execute_reply.started":"2024-11-30T12:28:50.260601Z"},"trusted":true},"outputs":[],"source":["# Compute field_dims\n","field_dims = [\n","    train_data['user id'].nunique(),\n","    train_data['movie id'].nunique(),\n","    train_data['gender'].nunique(),\n","    train_data['occupation'].nunique(),\n","    train_data['age'].nunique(),\n","    train_data['Action'].nunique(),\n","    train_data['Adventure'].nunique(),\n","    train_data['Animation'].nunique(),\n","    train_data['Children\\'s'].nunique(),\n","    train_data['Comedy'].nunique(),\n","    train_data['Crime'].nunique(),\n","    train_data['Documentary'].nunique(),\n","    train_data['Drama'].nunique(),\n","    train_data['Fantasy'].nunique(),\n","    train_data['Film-Noir'].nunique(),\n","    train_data['Horror'].nunique(),\n","    train_data['Musical'].nunique(),\n","    train_data['Mystery'].nunique(),\n","    train_data['Romance'].nunique(),\n","    train_data['Sci-Fi'].nunique(),\n","    train_data['Thriller'].nunique(),\n","    train_data['War'].nunique(),\n","    train_data['Western'].nunique(),\n","    train_data['unknown'].nunique()\n","]\n","\n","# Initialize datasets and loaders with device handling\n","train_dataset = MovieLensDataset(train_data, field_dims, device=device)\n","valid_dataset = MovieLensDataset(valid_data, field_dims, device=device)\n","test_dataset = MovieLensDataset(test_data, field_dims, device=device)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["[943, 1631, 2, 21, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["field_dims"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T12:28:50.271760Z","iopub.status.busy":"2024-11-30T12:28:50.271492Z"},"trusted":true},"outputs":[{"ename":"IndexError","evalue":"index out of range in self","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/Users/nguyenthanhbinh/Code Python/MovieRecSysWebMining/recsysdeepfm.ipynb Cell 10\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Initialize and train DeepFM model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m deepfm_model \u001b[39m=\u001b[39m DeepFM(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     field_dims\u001b[39m=\u001b[39mfield_dims,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     num_factors\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,  \u001b[39m# Embedding size\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     mlp_dims\u001b[39m=\u001b[39m[\u001b[39m128\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m32\u001b[39m],  \u001b[39m# MLP layers\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     drop_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m  \u001b[39m# Dropout rate\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train_deepfm(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     deepfm_model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     train_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     valid_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     test_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     num_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     lr\u001b[39m=\u001b[39;49m\u001b[39m5e-4\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n","\u001b[1;32m/Users/nguyenthanhbinh/Code Python/MovieRecSysWebMining/recsysdeepfm.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m features, target \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     predictions \u001b[39m=\u001b[39m model(features)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     loss \u001b[39m=\u001b[39m rmse_loss(predictions, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n","File \u001b[0;32m~/miniconda3/envs/vin_python/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/vin_python/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32m/Users/nguyenthanhbinh/Code Python/MovieRecSysWebMining/recsysdeepfm.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mForward pass of DeepFM.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m    torch.Tensor: Output tensor of shape (batch_size, 1).\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Embedding lookup\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m embed_x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     embed(x[:, i])\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m i, embed \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m ], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# Shape: (batch_size, num_fields, num_factors)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# FM: Second-order interactions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m square_of_sum \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(embed_x, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n","\u001b[1;32m/Users/nguyenthanhbinh/Code Python/MovieRecSysWebMining/recsysdeepfm.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mForward pass of DeepFM.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m    torch.Tensor: Output tensor of shape (batch_size, 1).\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Embedding lookup\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m embed_x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     embed(x[:, i])\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m i, embed \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m ], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# Shape: (batch_size, num_fields, num_factors)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# FM: Second-order interactions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nguyenthanhbinh/Code%20Python/MovieRecSysWebMining/recsysdeepfm.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m square_of_sum \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(embed_x, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/vin_python/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/vin_python/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/vin_python/lib/python3.11/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    164\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n","File \u001b[0;32m~/miniconda3/envs/vin_python/lib/python3.11/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n","\u001b[0;31mIndexError\u001b[0m: index out of range in self"]}],"source":["# Initialize and train DeepFM model\n","deepfm_model = DeepFM(\n","    field_dims=field_dims,\n","    num_factors=32,  # Embedding size\n","    mlp_dims=[128, 64, 32],  # MLP layers\n","    drop_rate=0.1  # Dropout rate\n",").to(device)\n","\n","train_deepfm(\n","    deepfm_model,\n","    train_loader,\n","    valid_loader,\n","    test_loader,\n","    num_epochs=10,\n","    lr=5e-4\n",")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":6197551,"sourceId":10057560,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
